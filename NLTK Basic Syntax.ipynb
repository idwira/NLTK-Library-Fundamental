{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments in Bahasa (Indonesia)\n",
    "# PR 1: Penggunaan Library NLTK/Spacy (Jan 2021)\n",
    "# Sumber teks: https://www.nytimes.com/2021/01/22/fashion/mens-style/rolex-biden.html\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To many, a president wearing a luxury watch might not seem unusual.', 'Shouldn’t the leader of the free world wear a power watch befitting his position?', 'Never mind that it costs the equivalent of dozen or so stimulus checks.']\n"
     ]
    }
   ],
   "source": [
    "# 1. SENTENCE SPLITTER\n",
    "\n",
    "# Mengubah text menjadi sentence\n",
    "# Sentence splitter adalah pemisahan teks menjadi kalimat-kalimat\n",
    "# Contoh penggalan teks dari satu paragraf berita di New York Times\n",
    "\n",
    "teksinput1 = 'To many, a president wearing a luxury watch might not seem unusual. Shouldn’t the leader of the free world wear a power watch befitting his position? Never mind that it costs the equivalent of dozen or so stimulus checks.'\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Modul 'sent_tokenize' menggunakan algoritma bawaan NLTK untuk melakukan sentence splitter, antara lain untuk\n",
    "# kalimat diatas adalah tanda titik dan tanda tanya.\n",
    "\n",
    "pemisahan = sent_tokenize(teksinput1)\n",
    "print(pemisahan)\n",
    "\n",
    "# Perhatikan pada output, teks diatas di split menjadi tiga bagian yg dipisahkan dgn tanda koma (,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To',\n",
       " 'many',\n",
       " ',',\n",
       " 'a',\n",
       " 'president',\n",
       " 'wearing',\n",
       " 'a',\n",
       " 'luxury',\n",
       " 'watch',\n",
       " 'might',\n",
       " 'not',\n",
       " 'seem',\n",
       " 'unusual',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. TOKENIZATION\n",
    "\n",
    "# Token atau Kata adalah unit terkecil yang dapat diproses oleh mesin.\n",
    "# Tokenisasi adalah proses memisahkan string menjadi token yang memiliki arti\n",
    "\n",
    "teksinput2 = 'To many, a president wearing a luxury watch might not seem unusual.'\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(teksinput2)\n",
    "\n",
    "# Modul 'word_tokenize' adalah metode tokenisasi yang umum dipakai untuk berbagai jenis corpus teks\n",
    "# Perhatikan pada output, teks dipisahkan berdasarkan spasi antar kata, tanda baca adalah termasuk token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "present continuous -> wearing : wear\n",
      "past tense -> wore : wore\n",
      "past participle -> worn : worn\n"
     ]
    }
   ],
   "source": [
    "# 3. STEMMING\n",
    "\n",
    "# Stemming adalah proses menemukan kata-kata dasar dari sebuah kata dengan rule yang sederhana yaitu dg memotong kata\n",
    "# Misal kata 'traveling' atau 'traveled' berasal dari kata dasar travel\n",
    "# Token dipangkas -> Stem (kata dasar)\n",
    "\n",
    "from nltk.stem import PorterStemmer #import PorterStemmer (utk B. Inggris)\n",
    "porter = PorterStemmer()\n",
    "print('present continuous -> wearing :',porter.stem('wearing'))\n",
    "print('past tense -> wore :',porter.stem('wore'))\n",
    "print('past participle -> worn :',porter.stem('worn'))\n",
    "\n",
    "# Perhatikan dari output, kata dasar dari present continuous 'wearing' adalah 'wear' di eksekusi benar\n",
    "# Namun bentuk past tense 'wore', tetap dituliskan 'wore' di output\n",
    "# Begitu pula dengan past participle 'worn', tetap dituliskan 'worn' ini adalah kelemahan Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "present continuous -> wearing : wear\n",
      "past tense -> wore : wear\n",
      "past participle -> worn : wear\n"
     ]
    }
   ],
   "source": [
    "# 4. LEMMATIZATION\n",
    "\n",
    "# Stemming lebih sederhana & cepat, namun tidak mencakup variasi tata-bahasa yang lebih kompleks\n",
    "# Untuk itu ada Lemmatization, yg lebih robust menerapkan aturan normalisasi utk menentukan akar kata\n",
    "# atau kata dasar (lemma)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer #Import WordNet dan lemmatizer\n",
    "wnlem = WordNetLemmatizer()\n",
    "print('present continuous -> wearing :', wnlem.lemmatize('wearing', pos='v'))\n",
    "print('past tense -> wore :', wnlem.lemmatize('wore', pos='v'))\n",
    "print('past participle -> worn :', wnlem.lemmatize('worn', pos='v'))\n",
    "\n",
    "# Perhatikan untuk mendapatkan hasil lemma yang akurat, jenis katanya mesti di tag dahulu\n",
    "# Untuk contoh diatas pos tag 'wear' adalah verb\n",
    "# Lemmatization dengan akurat mengeluarkan output kata dasarnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alamat email di teks :  ['biden@whitehouse.gov', 'philip@gmail.com']\n",
      "The new US President email is _email_ and his secretary email is _email_\n"
     ]
    }
   ],
   "source": [
    "# 5. ENTITY MASKING\n",
    "# Untuk melakukan masking yang mengikuti regular expression tertentu\n",
    "\n",
    "import re\n",
    "email = re.compile('\\w+@\\w+\\.[a-z]{3}') #rule untuk mendeteksi format entity email untuk di masking\n",
    "teks = \"The new US President email is biden@whitehouse.gov and his secretary email is philip@gmail.com\"\n",
    "print('Alamat email di teks : ',email.findall(teks))\n",
    "teks_mask=email.sub('_email_', teks)\n",
    "print(teks_mask)\n",
    "\n",
    "# Dengan rule ini dapat dilakukan masking untuk entity-entity tertentu seseuai regex yang diinginkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Wira\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('T', 'NNP'),\n",
       " ('o', 'MD'),\n",
       " (' ', 'VB'),\n",
       " ('m', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('n', 'JJ'),\n",
       " ('y', 'NN'),\n",
       " (',', ','),\n",
       " (' ', 'VB'),\n",
       " ('a', 'DT'),\n",
       " (' ', 'NN'),\n",
       " ('p', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('d', 'VBP'),\n",
       " ('e', 'NN'),\n",
       " ('n', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('w', 'NN'),\n",
       " ('e', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('r', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('n', 'VBP'),\n",
       " ('g', 'NN'),\n",
       " (' ', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " (' ', 'JJ'),\n",
       " ('l', 'NN'),\n",
       " ('u', 'JJ'),\n",
       " ('x', 'NNP'),\n",
       " ('u', 'NN'),\n",
       " ('r', 'NN'),\n",
       " ('y', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('w', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('t', 'JJ'),\n",
       " ('c', 'NN'),\n",
       " ('h', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('m', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('g', 'VBP'),\n",
       " ('h', 'NN'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('n', 'CC'),\n",
       " ('o', 'JJ'),\n",
       " ('t', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('s', 'NN'),\n",
       " ('e', 'NN'),\n",
       " ('e', 'VBP'),\n",
       " ('m', 'NN'),\n",
       " (' ', 'NNP'),\n",
       " ('u', 'JJ'),\n",
       " ('n', 'RB'),\n",
       " ('u', 'JJ'),\n",
       " ('s', 'NN'),\n",
       " ('u', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('l', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. POS Tagger\n",
    "# Adalah tool untuk tag pos setiap kata di teks input\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.pos_tag(teksinput2)\n",
    "\n",
    "# Perhatikan pada output masih ada yang kurang tepat, dimana 'T' di tag NNP\n",
    "# Begitu juga dg beberapa spasi antara kata juga di labeli Proper Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP last/JJ night/NN)\n",
      "  (NP i/NN)\n",
      "  saw/VBD\n",
      "  (NP a/DT black/JJ dog/NN)\n",
      "  (NP barking/NN)\n",
      "  at/IN\n",
      "  (NP a/DT kid/NN))\n"
     ]
    }
   ],
   "source": [
    "# 7. PHRASE CHUNKING\n",
    "# Mencari semua bentuk frase yang non-rekursif\n",
    "\n",
    "gram = (\"NP: {<DT>?<JJ>*<NN>}\") #Grammar yang akan dipakai chunking\n",
    "kalimat = 'last night i saw a black dog barking at a kid'\n",
    "\n",
    "chunking = nltk.RegexpParser(gram) #fungsi RegexParser NLTK\n",
    "kalimat_token = nltk.word_tokenize(kalimat) #tokenisasi kalimat\n",
    "tagging = nltk.pos_tag(kalimat_token) #pos tag\n",
    "tagging\n",
    "\n",
    "tree = chunking.parse(tagging) #proses chunking frase\n",
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
